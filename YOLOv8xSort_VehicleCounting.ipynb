{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fediltf/YOLOv8xSort_VehicleCounting/blob/main/YOLOv8xSort_VehicleCounting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # Vehicle Detection, Tracking, and Counting with YOLOv8 and SORT\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "***Mohamed Fedi LETAIEF***\n"
      ],
      "metadata": {
        "id": "SGmftPgeN1bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries, modules and files"
      ],
      "metadata": {
        "id": "LlbswXrtOIi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd() # GET current work directory\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxsClQKWORo8",
        "outputId": "547ba825-2fc9-43ff-dbf0-fdf83f4763fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install filterpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB2P7LTgOYSF",
        "outputId": "69dae64f-19f0-47d4-d3eb-b7c1d1e1db01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.0-py3-none-any.whl (699 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.2/699.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Collecting hub-sdk>=0.0.2 (from ultralytics)\n",
            "  Downloading hub_sdk-0.0.2-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: hub-sdk, thop, ultralytics\n",
            "Successfully installed hub-sdk-0.0.2 thop-0.1.1.post2209072238 ultralytics-8.1.0\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=edff73ec1ba7cca9fa9cb04dd9303abba067e8fea03529d929717fac962a9c0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built filterpy\n",
            "Installing collected packages: filterpy\n",
            "Successfully installed filterpy-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO\n",
        "from numpy import random\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd {HOME}\n",
        "%cp /content/drive/MyDrive/sort.py sort.py\n",
        "import sort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj9D_rtdOb1V",
        "outputId": "950653ed-3f47-4b07-f5e8-574515b9ea38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.0 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n",
            "Mounted at /content/drive\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the YOLOv8_ObjectDetector Class for object detection:"
      ],
      "metadata": {
        "id": "Bn-zmfZYPNFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOv8_ObjectDetector:\n",
        "\n",
        "  def __init__(self, model_file = 'yolov8n.pt', labels= None, classes = None, conf = 0.25, iou = 0.45 ):\n",
        "    self.classes = classes\n",
        "    self.conf = conf\n",
        "    self.iou = iou\n",
        "\n",
        "    self.model = YOLO(model_file)\n",
        "    self.model_name = model_file.split('.')[0]\n",
        "    self.results = None\n",
        "\n",
        "    # if no labels are provided then use default COCO names\n",
        "    if labels == None:\n",
        "        self.labels = self.model.names\n",
        "    else:\n",
        "        self.labels = labels\n",
        "\n",
        "  def predict_img(self, img, verbose=True):\n",
        "    # Run the model on the input image with the given parameters\n",
        "    results = self.model(img, classes=self.classes, conf=self.conf, iou=self.iou, verbose=verbose)\n",
        "\n",
        "    # Save the original image and the results for further analysis if needed\n",
        "    self.orig_img = img\n",
        "    self.results = results[0]\n",
        "\n",
        "    # Return the detection results\n",
        "    return results[0]\n",
        "\n",
        "\n",
        "\n",
        "  def default_display(self, show_conf=True, line_width=None, font_size=None, font='Arial.ttf', pil=False, example='abc'):\n",
        "\n",
        "    # Check if the `predict_img()` method has been called before displaying the detected objects\n",
        "    if self.results is None:\n",
        "        raise ValueError('No detected objects to display. Call predict_img() method first.')\n",
        "\n",
        "    # Call the plot() method of the `self.results` object to display the detected objects on the original image\n",
        "    display_img = self.results.plot(show_conf, line_width, font_size, font, pil, example)\n",
        "\n",
        "    # Return the displayed image\n",
        "    return display_img\n",
        "\n",
        "\n",
        "\n",
        "  def custom_display(self, colors, show_cls = True, show_conf = True):\n",
        "\n",
        "    img = self.orig_img\n",
        "    # calculate the bounding box thickness based on the image width and height\n",
        "    bbx_thickness = (img.shape[0] + img.shape[1]) // 450\n",
        "\n",
        "    for box in self.results.boxes:\n",
        "        textString = \"\"\n",
        "\n",
        "        # Extract object class and confidence score\n",
        "        score = box.conf.item() * 100\n",
        "        class_id = int(box.cls.item())\n",
        "\n",
        "        x1 , y1 , x2, y2 = np.squeeze(box.xyxy.cpu().numpy()).astype(int)\n",
        "\n",
        "        # Print detection info\n",
        "        if show_cls:\n",
        "            textString += f\"{self.labels[class_id]}\"\n",
        "\n",
        "        if show_conf:\n",
        "            textString += f\" {score:,.2f}%\"\n",
        "\n",
        "        # Calculate font scale based on object size\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX\n",
        "        fontScale = (((x2 - x1) / img.shape[0]) + ((y2 - y1) / img.shape[1])) / 2 * 2.5\n",
        "        fontThickness = 1\n",
        "        textSize, baseline = cv2.getTextSize(textString, font, fontScale, fontThickness)\n",
        "\n",
        "        # Draw bounding box, a centroid and label on the image\n",
        "        img = cv2.rectangle(img, (x1,y1), (x2,y2), colors[class_id], bbx_thickness)\n",
        "        center_coordinates = ((x1 + x2)//2, (y1 + y2) // 2)\n",
        "\n",
        "        img =  cv2.circle(img, center_coordinates, 5 , (0,0,255), -1)\n",
        "\n",
        "          # If there are no details to show on the image\n",
        "        if textString != \"\":\n",
        "            if (y1 < textSize[1]):\n",
        "                y1 = y1 + textSize[1]\n",
        "            else:\n",
        "                y1 -= 2\n",
        "            # show the details text in a filled rectangle\n",
        "            img = cv2.rectangle(img, (x1, y1), (x1 + textSize[0] , y1 -  textSize[1]), colors[class_id], cv2.FILLED)\n",
        "            img = cv2.putText(img, textString ,\n",
        "                (x1, y1), font,\n",
        "                fontScale,  (0, 0, 0), fontThickness, cv2.LINE_AA)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "  def predict_video(self, video_path, save_dir, save_format=\"avi\", display='custom', verbose=True, **display_args):\n",
        "\n",
        "    # Open the input video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the name of the input video file\n",
        "    vid_name = os.path.basename(video_path)\n",
        "\n",
        "    # Get the dimensions of each frame in the input video file\n",
        "    width = int(cap.get(3))  # get `width`\n",
        "    height = int(cap.get(4))  # get `height`\n",
        "\n",
        "    # Create the directory for the output video file if it does not already exist\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    # Set the name and path for the output video file\n",
        "    save_name = self.model_name + ' -- ' + vid_name.split('.')[0] + '.' + save_format\n",
        "    save_file = os.path.join(save_dir, save_name)\n",
        "\n",
        "    # Print information about the input and output video files if verbose is True\n",
        "    if verbose:\n",
        "        print(\"----------------------------\")\n",
        "        print(f\"DETECTING OBJECTS IN : {vid_name} : \")\n",
        "        print(f\"RESOLUTION : {width}x{height}\")\n",
        "        print('SAVING TO :' + save_file)\n",
        "\n",
        "    # Define an output VideoWriter object\n",
        "    out = cv2.VideoWriter(save_file,\n",
        "                          cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
        "                          30, (width, height))\n",
        "\n",
        "    # Check if the input video file was opened correctly\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video stream or file\")\n",
        "\n",
        "    # Read each frame of the input video file\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        # If the frame was not read successfully, break the loop\n",
        "        if not ret:\n",
        "            print(\"Error reading frame\")\n",
        "            break\n",
        "\n",
        "        # Run object detection on the frame and calculate FPS\n",
        "        beg = time.time()\n",
        "        results = self.predict_img(frame, verbose=False)\n",
        "        if results is None:\n",
        "            print('***********************************************')\n",
        "        fps = 1 / (time.time() - beg)\n",
        "\n",
        "        # Display the detection results\n",
        "        if display == 'default':\n",
        "            frame = self.default_display(**display_args)\n",
        "        elif display == 'custom':\n",
        "            frame == self.custom_display(**display_args)\n",
        "\n",
        "        # Display the FPS on the frame\n",
        "        frame = cv2.putText(frame, f\"FPS : {fps:,.2f}\",\n",
        "                            (5, 15), cv2.FONT_HERSHEY_COMPLEX,\n",
        "                            0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "        # Write the frame to the output video file\n",
        "        out.write(frame)\n",
        "\n",
        "\n",
        "    # After the loop release the cap and video writer\n",
        "    cap.release()\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "v0cX5tCaO4Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the YOLOv8_ObjectCounter Class for object counting:"
      ],
      "metadata": {
        "id": "sII8ip2xPqHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOv8_ObjectCounter(YOLOv8_ObjectDetector):\n",
        "\n",
        "    def __init__(self, model_file = 'yolov8n.pt', labels= None, classes = None, conf = 0.25, iou = 0.45,\n",
        "                 track_max_age = 45, track_min_hits= 15, track_iou_threshold = 0.3 ):\n",
        "\n",
        "        super().__init__(model_file , labels, classes, conf, iou)\n",
        "\n",
        "        self.track_max_age = track_max_age\n",
        "        self.track_min_hits = track_min_hits\n",
        "        self.track_iou_threshold = track_iou_threshold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def predict_video(self, video_path, save_dir, save_format = \"avi\",\n",
        "                      display = 'custom', verbose = True, **display_args):\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        # Get video name\n",
        "        vid_name = os.path.basename(video_path)\n",
        "\n",
        "\n",
        "        # Get frame dimensions and print information about input video file\n",
        "        width  = int(cap.get(3) )  # get `width`\n",
        "        height = int(cap.get(4) )  # get `height`\n",
        "\n",
        "        if not os.path.isdir(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        save_name = self.model_name + ' -- ' + vid_name.split('.')[0] + '.' + save_format\n",
        "        save_file = os.path.join(save_dir, save_name)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"----------------------------\")\n",
        "            print(f\"DETECTING OBJECTS IN : {vid_name} : \")\n",
        "            print(f\"RESOLUTION : {width}x{height}\")\n",
        "            print('SAVING TO :' + save_file)\n",
        "\n",
        "        # define an output VideoWriter  object\n",
        "        out = cv2.VideoWriter(save_file,\n",
        "                            cv2.VideoWriter_fourcc(*\"MJPG\"),\n",
        "                            30,(width,height))\n",
        "\n",
        "        # Check if the video is opened correctly\n",
        "        if not cap.isOpened():\n",
        "            print(\"Error opening video stream or file\")\n",
        "\n",
        "        # Initialize object tracker\n",
        "        tracker = sort.Sort(max_age = self.track_max_age, min_hits= self.track_min_hits ,\n",
        "                            iou_threshold = self.track_iou_threshold)\n",
        "\n",
        "        # Initialize variables for object counting\n",
        "        totalCount = []\n",
        "        currentArray = np.empty((0, 5))\n",
        "\n",
        "\n",
        "        # Read the video frames\n",
        "        while cap.isOpened():\n",
        "\n",
        "            detections = np.empty((0, 5))\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            # If the frame was not read successfully, break the loop\n",
        "            if not ret:\n",
        "                print(\"Error reading frame\")\n",
        "                break\n",
        "\n",
        "            # Run object detection on the frame and calculate FPS\n",
        "            beg = time.time()\n",
        "            results = self.predict_img(frame, verbose = False)\n",
        "            if results == None:\n",
        "                print('***********************************************')\n",
        "            fps = 1 / (time.time() - beg)\n",
        "            for box in results.boxes:\n",
        "                score = box.conf.item() * 100\n",
        "                class_id = int(box.cls.item())\n",
        "\n",
        "                x1 , y1 , x2, y2 = np.squeeze(box.xyxy.cpu().numpy()).astype(int)\n",
        "\n",
        "                currentArray = np.array([x1, y1, x2, y2, score])\n",
        "                detections = np.vstack((detections, currentArray))\n",
        "\n",
        "            # Update object tracker\n",
        "            resultsTracker = tracker.update(detections)\n",
        "            for result in resultsTracker:\n",
        "                #print(type(result))\n",
        "\n",
        "                # Get the tracker results\n",
        "                x1, y1, x2, y2, id = result\n",
        "                x1, y1, x2, y2, id = int(x1), int(y1), int(x2), int(y2), int(id)\n",
        "                #print(result)\n",
        "\n",
        "                # Display current objects IDs\n",
        "                w, h = x2 - x1, y2 - y1\n",
        "                cx, cy = x1 + w // 2, y1 + h // 2\n",
        "                id_txt = f\"ID: {str(id)}\"\n",
        "                cv2.putText(frame, id_txt, (cx, cy), 4, 0.5, (0, 0, 255), 1)\n",
        "\n",
        "                # if we haven't seen aprticular object ID before, register it in a list\n",
        "                if totalCount.count(id) == 0:\n",
        "                    totalCount.append(id)\n",
        "\n",
        "            # Display detection results\n",
        "            if display == 'default':\n",
        "                frame = self.default_display(**display_args)\n",
        "\n",
        "            elif display == 'custom':\n",
        "                frame == self.custom_display( **display_args)\n",
        "\n",
        "            # Display FPS on frame\n",
        "            frame = cv2.putText(frame,f\"FPS : {fps:,.2f}\" ,\n",
        "                                (5,55), cv2.FONT_HERSHEY_COMPLEX,\n",
        "                            0.5,  (0,255,255), 1, cv2.LINE_AA)\n",
        "\n",
        "            # Display Counting results\n",
        "            count_txt = f\"TOTAL COUNT : {len(totalCount)}\"\n",
        "            frame = cv2.putText(frame, count_txt, (5,45), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "            # append frame to the video file\n",
        "            out.write(frame)\n",
        "\n",
        "        # After the loop release the cap\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(len(totalCount))\n",
        "        print(totalCount)"
      ],
      "metadata": {
        "id": "FE2GvrWuPmZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiating object detectors and counters with different YOLOv8 model variants"
      ],
      "metadata": {
        "id": "4680LrgJQGeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_names = ['yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt']\n",
        "colors = []\n",
        "for _ in range(80):\n",
        "    rand_tuple = (random.randint(50, 255), random.randint(50, 255), random.randint(50, 255))\n",
        "    colors.append(rand_tuple)\n",
        "\n",
        "detectors = []\n",
        "for yolo_name in yolo_names:\n",
        "    detector = YOLOv8_ObjectDetector(yolo_name, conf = 0.60 )\n",
        "    detectors.append(detector)\n",
        "\n",
        "counters = []\n",
        "for yolo_name in yolo_names:\n",
        "    counter = YOLOv8_ObjectCounter(yolo_name, conf = 0.60 )\n",
        "    counters.append(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdsIlYXAQXcB",
        "outputId": "59430b11-d8c8-44bb-f0c4-394891fac35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 302MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 364MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 128MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8l.pt to 'yolov8l.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83.7M/83.7M [00:00<00:00, 270MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131M/131M [00:00<00:00, 163MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing directories and file-paths"
      ],
      "metadata": {
        "id": "FCzFGoHzpb49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vid_results_path = '/content/drive/MyDrive/YOLOv8xSort_VehicleCounting/video_results'\n",
        "\n",
        "if not os.path.isdir(vid_results_path):\n",
        "    os.makedirs(vid_results_path)"
      ],
      "metadata": {
        "id": "Y-xXMgUjiX_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print diffirent detector labels"
      ],
      "metadata": {
        "id": "fZlqzLfBS7iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = YOLOv8_ObjectDetector()\n",
        "for i in d.labels.values():\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGtV8BgBRpqt",
        "outputId": "7c3af956-f2c1-4522-8f6e-3ad0cbf67ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person\n",
            "bicycle\n",
            "car\n",
            "motorcycle\n",
            "airplane\n",
            "bus\n",
            "train\n",
            "truck\n",
            "boat\n",
            "traffic light\n",
            "fire hydrant\n",
            "stop sign\n",
            "parking meter\n",
            "bench\n",
            "bird\n",
            "cat\n",
            "dog\n",
            "horse\n",
            "sheep\n",
            "cow\n",
            "elephant\n",
            "bear\n",
            "zebra\n",
            "giraffe\n",
            "backpack\n",
            "umbrella\n",
            "handbag\n",
            "tie\n",
            "suitcase\n",
            "frisbee\n",
            "skis\n",
            "snowboard\n",
            "sports ball\n",
            "kite\n",
            "baseball bat\n",
            "baseball glove\n",
            "skateboard\n",
            "surfboard\n",
            "tennis racket\n",
            "bottle\n",
            "wine glass\n",
            "cup\n",
            "fork\n",
            "knife\n",
            "spoon\n",
            "bowl\n",
            "banana\n",
            "apple\n",
            "sandwich\n",
            "orange\n",
            "broccoli\n",
            "carrot\n",
            "hot dog\n",
            "pizza\n",
            "donut\n",
            "cake\n",
            "chair\n",
            "couch\n",
            "potted plant\n",
            "bed\n",
            "dining table\n",
            "toilet\n",
            "tv\n",
            "laptop\n",
            "mouse\n",
            "remote\n",
            "keyboard\n",
            "cell phone\n",
            "microwave\n",
            "oven\n",
            "toaster\n",
            "sink\n",
            "refrigerator\n",
            "book\n",
            "clock\n",
            "vase\n",
            "scissors\n",
            "teddy bear\n",
            "hair drier\n",
            "toothbrush\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing object detection, tracking and counting"
      ],
      "metadata": {
        "id": "k8HV-cgSUJx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for counter in counters:\n",
        "    counter.predict_video(video_path= '/content/drive/MyDrive/YOLOv8xSort_VehicleCounting/test_videos/traffic.mp4', save_dir = vid_results_path, save_format = \"avi\", display = 'custom', colors = colors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHmPCPH4T7KH",
        "outputId": "082952a0-af8a-45b1-988a-49240297a54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "DETECTING OBJECTS IN : traffic.mp4 : \n",
            "RESOLUTION : 1280x720\n",
            "SAVING TO :/content/drive/MyDrive/YOLOv8xSort_VehicleCounting/video_results/yolov8n -- traffic.avi\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "Error reading frame\n",
            "26\n",
            "[8, 7, 6, 5, 4, 3, 2, 1, 9, 10, 12, 11, 13, 15, 17, 18, 19, 21, 22, 26, 27, 25, 29, 30, 32, 33]\n",
            "----------------------------\n",
            "DETECTING OBJECTS IN : traffic.mp4 : \n",
            "RESOLUTION : 1280x720\n",
            "SAVING TO :/content/drive/MyDrive/YOLOv8xSort_VehicleCounting/video_results/yolov8s -- traffic.avi\n",
            "Error reading frame\n",
            "20\n",
            "[43, 42, 41, 40, 39, 38, 44, 47, 45, 48, 54, 57, 61, 63, 66, 70, 69, 71, 76, 77]\n",
            "----------------------------\n",
            "DETECTING OBJECTS IN : traffic.mp4 : \n",
            "RESOLUTION : 1280x720\n",
            "SAVING TO :/content/drive/MyDrive/YOLOv8xSort_VehicleCounting/video_results/yolov8m -- traffic.avi\n",
            "Error reading frame\n",
            "25\n",
            "[86, 85, 84, 83, 82, 81, 87, 88, 89, 90, 91, 92, 98, 99, 101, 104, 103, 105, 100, 109, 112, 107, 113, 116, 117]\n",
            "----------------------------\n",
            "DETECTING OBJECTS IN : traffic.mp4 : \n",
            "RESOLUTION : 1280x720\n",
            "SAVING TO :/content/drive/MyDrive/YOLOv8xSort_VehicleCounting/video_results/yolov8l -- traffic.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "clip = VideoFileClip(\"/content/drive/MyDrive/YOLOv8xSort_VehicleCounting/video_results/yolov8n -- traffic.avi\")\n",
        "clip.write_gif(\"/content/drive/MyDrive/YOLOv8xSort_VehicleCounting/video_results/yolov8n -- traffic.gif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUwORuL8W3Ce",
        "outputId": "86208542-9973-4105-ec67-161a415b2d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Building file /content/drive/MyDrive/YOLOv8xSort_VehicleCounting/video_results/yolov8n -- traffic.gif with imageio.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        }
      ]
    }
  ]
}